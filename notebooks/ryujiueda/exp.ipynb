{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d9382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, numpy as np, pandas as pd\n",
    "import tensorflow_decision_forests as tfdf\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "DATA_DIR = \"/kaggle/input/spaceship-titanic-ut-komaba-2025\"\n",
    "WORK_DIR = \"/kaggle/working\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "train = pd.read_csv(f\"{DATA_DIR}/train.csv\")\n",
    "test  = pd.read_csv(f\"{DATA_DIR}/test.csv\")\n",
    "sample_sub = pd.read_csv(f\"{DATA_DIR}/sample_submission.csv\")\n",
    "\n",
    "SPEND_COLS = [\"RoomService\",\"FoodCourt\",\"ShoppingMall\",\"Spa\",\"VRDeck\"]\n",
    "\n",
    "# ---------- 前処理（学習/推論で完全一致） ----------\n",
    "def preprocess(df: pd.DataFrame, *, training: bool):\n",
    "    X = df.copy()\n",
    "\n",
    "    # groupは検証用にだけ使う（特徴には入れない）\n",
    "    X[\"__Group__\"] = X[\"PassengerId\"].astype(str).str.split(\"_\").str[0]\n",
    "\n",
    "    # Cabin 分解\n",
    "    parts = X[\"Cabin\"].astype(str).str.split(\"/\", expand=True)\n",
    "    X[\"Deck\"] = parts[0].replace({\"nan\": np.nan})\n",
    "    X[\"Cabin_num\"] = pd.to_numeric(parts[1], errors=\"coerce\")\n",
    "    X[\"Side\"] = parts[2].replace({\"nan\": np.nan})\n",
    "    X.drop(columns=[\"Cabin\"], inplace=True)\n",
    "\n",
    "    # Booleans → 0/1\n",
    "    for c in [\"CryoSleep\",\"VIP\"]:\n",
    "        if c in X.columns:\n",
    "            X[c] = X[c].fillna(False).astype(int)\n",
    "\n",
    "    # 支出：CryoSleep==1 の NA は 0、その他の NA も 0\n",
    "    if \"CryoSleep\" in X.columns:\n",
    "        mask = X[\"CryoSleep\"] == 1\n",
    "        for c in SPEND_COLS:\n",
    "            if c in X.columns:\n",
    "                X.loc[mask & X[c].isna(), c] = 0\n",
    "    for c in SPEND_COLS:\n",
    "        if c in X.columns:\n",
    "            X[c] = X[c].fillna(0)\n",
    "\n",
    "    # 合計/派生\n",
    "    X[\"TotalSpend\"] = X[SPEND_COLS].sum(axis=1, min_count=1).fillna(0)\n",
    "    X[\"NoSpend\"] = (X[\"TotalSpend\"] == 0).astype(int)\n",
    "    X[\"TotalSpend_log1p\"] = np.log1p(X[\"TotalSpend\"])\n",
    "\n",
    "    # Age 補完（HomePlanet×Deck→全体中央値）\n",
    "    if \"Age\" in X.columns:\n",
    "        grp_med = X.groupby([\"HomePlanet\",\"Deck\"])[\"Age\"].transform(\"median\")\n",
    "        X[\"Age\"] = X[\"Age\"].fillna(grp_med)\n",
    "        X[\"Age\"] = X[\"Age\"].fillna(X[\"Age\"].median())\n",
    "        X[\"IsChild\"] = (X[\"Age\"] < 13).astype(int)\n",
    "        X[\"IsTeen\"]  = ((X[\"Age\"] >= 13) & (X[\"Age\"] < 20)).astype(int)\n",
    "\n",
    "    # カテゴリ NA → \"Unknown\"\n",
    "    for c in [\"HomePlanet\",\"Destination\",\"Deck\",\"Side\"]:\n",
    "        if c in X.columns:\n",
    "            X[c] = X[c].fillna(\"Unknown\")\n",
    "\n",
    "    # 学習時だけ label を保持\n",
    "    y = None\n",
    "    if training:\n",
    "        y = X[\"Transported\"].astype(int).values\n",
    "        X = X.drop(columns=[\"Transported\"])\n",
    "\n",
    "    # 強い識別子は削除（Groupは残すが特徴には入れない）\n",
    "    for col in [\"PassengerId\",\"Name\"]:\n",
    "        if col in X.columns:\n",
    "            X.drop(columns=[col], inplace=True)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X_train, y = preprocess(train, training=True)\n",
    "X_test, _   = preprocess(test,  training=False)\n",
    "\n",
    "# ---------- 1) スモークテスト群 ----------\n",
    "def assert_no_mismatch_columns():\n",
    "    cols_train = set(X_train.columns) - {\"__Group__\"}\n",
    "    cols_test  = set(X_test.columns) - {\"__Group__\"}\n",
    "    assert cols_train == cols_test, f\"列ずれ検出: train={len(cols_train)} cols, test={len(cols_test)} cols, 差分={sorted(list(cols_train ^ cols_test))}\"\n",
    "\n",
    "def assert_spend_symmetry():\n",
    "    # 支出列（train/testともに NA 0化できているか）\n",
    "    for c in SPEND_COLS:\n",
    "        assert X_train[c].isna().sum()==0, f\"trainの {c} にNAが残っています\"\n",
    "        assert X_test[c].isna().sum()==0,  f\"test の {c} にNAが残っています\"\n",
    "\n",
    "def assert_basic_dtypes():\n",
    "    # CryoSleep/VIP が 0/1 か\n",
    "    for c in [\"CryoSleep\",\"VIP\"]:\n",
    "        assert set(X_train[c].unique()) <= {0,1}, f\"{c} が 0/1 ではありません（train）\"\n",
    "        assert set(X_test[c].unique())  <= {0,1}, f\"{c} が 0/1 ではありません（test）\"\n",
    "    # 代表数値が数値型か\n",
    "    for c in [\"Age\",\"Cabin_num\",\"TotalSpend\",\"TotalSpend_log1p\"]:\n",
    "        assert c in X_train.columns, f\"列が見つかりません: {c}\"\n",
    "        assert pd.api.types.is_numeric_dtype(X_train[c]), f\"{c} が数値型ではありません（train）\"\n",
    "        assert pd.api.types.is_numeric_dtype(X_test[c]),  f\"{c} が数値型ではありません（test）\"\n",
    "\n",
    "def assert_no_missing_after_preprocess():\n",
    "    # 特徴にNAが残っていないか（木系はNA扱えるが、意図しないNAを検知したい）\n",
    "    feat_cols = [c for c in X_train.columns if c != \"__Group__\"]\n",
    "    assert X_train[feat_cols].isna().sum().sum()==0, \"trainの特徴にNAが残っています\"\n",
    "    assert X_test[feat_cols].isna().sum().sum()==0,  \"test の特徴にNAが残っています\"\n",
    "\n",
    "assert_no_mismatch_columns()\n",
    "assert_spend_symmetry()\n",
    "assert_basic_dtypes()\n",
    "assert_no_missing_after_preprocess()\n",
    "\n",
    "print(\"✓ スモークテスト: 前処理の一致 / 欠損 / 型 → OK\")\n",
    "\n",
    "# ---------- 2) リーク検査（GroupKFoldでグループ交差なしを保証） ----------\n",
    "groups = X_train[\"__Group__\"].values\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "for i, (tr_idx, va_idx) in enumerate(gkf.split(X_train, y, groups), 1):\n",
    "    overlap = set(groups[tr_idx]) & set(groups[va_idx])\n",
    "    assert len(overlap)==0, f\"fold{i}: GroupKFoldでグループが重複（リーク）: {list(overlap)[:5]}\"\n",
    "print(\"✓ リーク検査: GroupKFold のグループ重複なし → OK\")\n",
    "\n",
    "# ---------- 3) クイックCV（1 foldだけ・小さめ木） ----------\n",
    "#   *目的*: ランダム・ベースラインを超えるか（安全ラインを 0.70 に設定）\n",
    "def quick_cv_one_fold_accuracy_threshold(threshold=0.70):\n",
    "    # 1 foldだけ回す（高速）\n",
    "    tr_idx, va_idx = next(iter(gkf.split(X_train, y, groups)))\n",
    "    # TF-DF は pandas→tf.data に変換して学習\n",
    "    label_col = \"__label__\"\n",
    "    # 特徴から __Group__ を外す\n",
    "    feat_cols = [c for c in X_train.columns if c != \"__Group__\"]\n",
    "    df_tr = X_train.iloc[tr_idx][feat_cols].copy()\n",
    "    df_va = X_train.iloc[va_idx][feat_cols].copy()\n",
    "    df_tr[label_col] = y[tr_idx]\n",
    "    df_va[label_col] = y[va_idx]\n",
    "\n",
    "    ds_tr = tfdf.keras.pd_dataframe_to_tf_dataset(df_tr, label=label_col)\n",
    "    ds_va = tfdf.keras.pd_dataframe_to_tf_dataset(df_va, label=label_col)\n",
    "\n",
    "    model = tfdf.keras.GradientBoostedTreesModel(\n",
    "        num_trees=300,  # 小さめ\n",
    "        max_depth=6,\n",
    "        subsample=0.9,\n",
    "        verbose=0,\n",
    "        random_seed=RANDOM_STATE,\n",
    "    )\n",
    "    model.compile(metrics=[\"accuracy\"])\n",
    "    model.fit(ds_tr)\n",
    "    eval_dict = model.evaluate(ds_va, return_dict=True, verbose=0)\n",
    "    acc = float(eval_dict[\"accuracy\"])\n",
    "    print(f\"Quick CV (1-fold) Accuracy: {acc:.4f}\")\n",
    "    assert acc >= threshold, f\"QuickCV精度が閾値未満: acc={acc:.4f} < {threshold:.2f}\"\n",
    "    return acc\n",
    "\n",
    "_ = quick_cv_one_fold_accuracy_threshold(threshold=0.70)\n",
    "print(\"✓ クイックCV: 1-fold精度が最低ラインをクリア → OK\")\n",
    "\n",
    "# ---------- 4) 擬似提出テスト（形だけ確認・提出はしない） ----------\n",
    "# 最終的な推論パスが壊れていないか、行数・列名・型だけ確認\n",
    "def pseudo_submit_shape_check():\n",
    "    feat_cols = [c for c in X_train.columns if c != \"__Group__\"]\n",
    "    # full-train（小さめ構成）\n",
    "    df_full = X_train[feat_cols].copy()\n",
    "    df_full[\"__label__\"] = y\n",
    "    ds_full = tfdf.keras.pd_dataframe_to_tf_dataset(df_full, label=\"__label__\")\n",
    "    model = tfdf.keras.GradientBoostedTreesModel(\n",
    "        num_trees=350, max_depth=6, subsample=0.9, verbose=0, random_seed=RANDOM_STATE\n",
    "    )\n",
    "    model.compile(metrics=[\"accuracy\"])\n",
    "    model.fit(ds_full, verbose=0)\n",
    "\n",
    "    ds_test = tfdf.keras.pd_dataframe_to_tf_dataset(X_test[feat_cols])\n",
    "    preds = model.predict(ds_test, verbose=0).squeeze()\n",
    "    # TF-DFは確率（Positiveクラス）を返す構成を想定\n",
    "    assert preds.shape[0] == len(test), \"予測数がtest行数と一致しません\"\n",
    "    assert np.isfinite(preds).all(), \"予測に非有限値が含まれています\"\n",
    "    pred_bool = (preds >= 0.5)\n",
    "    out = sample_sub.copy()\n",
    "    out[\"Transported\"] = pred_bool\n",
    "    out_path = os.path.join(WORK_DIR, \"submission_TEST.csv\")\n",
    "    out.to_csv(out_path, index=False)\n",
    "    # 形状チェック\n",
    "    chk = pd.read_csv(out_path)\n",
    "    assert list(chk.columns)==[\"PassengerId\",\"Transported\"], \"提出列名が不正です\"\n",
    "    assert chk[\"PassengerId\"].dtype == sample_sub[\"PassengerId\"].dtype, \"PassengerIdのdtypeが想定と異なります\"\n",
    "    assert chk[\"Transported\"].dtype == bool, \"Transportedはboolであるべきです\"\n",
    "    print(f\"✓ 擬似提出: 形状チェックOK → {out_path}\")\n",
    "\n",
    "pseudo_submit_shape_check()\n",
    "\n",
    "print(\"\\n=== All tests passed ===\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
