{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":117304,"databundleVersionId":14020814,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import StratifiedGroupKFold\nimport catboost as cb\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nimport warnings\n\nwarnings.filterwarnings('ignore', category=UserWarning)\n\n# Load datasets\ntrain = pd.read_csv('/kaggle/input/spaceship-titanic-ut-komaba-2025/train.csv')\ntest = pd.read_csv('/kaggle/input/spaceship-titanic-ut-komaba-2025/test.csv')\n\n# =========================================================\n# 1. 特徴量エンジニアリング\n# =========================================================\ndef create_features(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"欠損値を補完せずに特徴量を生成する\"\"\"\n    data = df.copy()\n    \n    # Cabin情報を分解（欠損はNaNのまま保持）\n    if 'Cabin' in data.columns:\n        cabin_split = data['Cabin'].str.split('/', expand=True)\n        data['Deck'] = cabin_split[0]\n        data['Num'] = pd.to_numeric(cabin_split[1], errors='coerce')\n        data['Side'] = cabin_split[2]\n    else:\n        data['Deck'] = np.nan\n        data['Num'] = np.nan\n        data['Side'] = np.nan\n\n    # 支出関連特徴量（NaNはそのまま残す）\n    expense_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n    two_expense = ['FoodCourt', 'ShoppingMall']\n    three_expense = ['RoomService', 'Spa', 'VRDeck']\n    for col in expense_cols:\n        if col not in data.columns:\n            data[col] = np.nan\n\n    # 総支出額（NaNのまま計算 → NaNを含む場合はNaN）\n    data['TotalExpense'] = data[expense_cols].sum(axis=1, skipna=False)\n    data['TwoExpense'] = data[two_expense].sum(axis=1, skipna=False)\n    data['ThreeExpense'] = data[three_expense].sum(axis=1, skipna=False)\n    data['HasExpense'] = data[expense_cols].gt(0).any(axis=1).astype(int)\n\n    # 年齢グループ（NaNは'Unknown'にせず、NaNのまま）\n    bins = [0, 7, 14, 21, 50, 100]\n    labels = ['Child', 'Teen', 'Young', 'Adult', 'Senior']\n    data['AgeGroup'] = pd.cut(data['Age'], bins=bins, labels=labels)\n\n    # Name情報から家族サイズを生成（欠損はNaN）\n    if 'Name' in data.columns:\n        data['FamilyName'] = data['Name'].str.split().str[-1]\n        family_counts = data['FamilyName'].value_counts()\n        data['FamilySize'] = data['FamilyName'].map(family_counts)\n        data['IsAlone'] = (data['FamilySize'] == 1).astype(int)\n    # PassengerId情報（欠損時はNaN）\n    if 'PassengerId' in data.columns:\n        passenger_split = data['PassengerId'].str.split('_', expand=True)\n        data['PassengerGroup'] = passenger_split[0]\n        data['PassengerNum'] = pd.to_numeric(passenger_split[1], errors='coerce')\n        \n    # 組み合わせ特徴量の追加\n    num_bins = [0, 250, 500, 750, 2000]\n    num_labels = ['Q1', 'Q2', 'Q3', 'Q4']\n    data['NumQuartile'] = pd.cut(data['Num'], bins=num_bins, labels=num_labels, right=False)\n    data['Cabin_Loc'] = data['Deck'].astype(str) + '_' + data['NumQuartile'].astype(str)\n    data['NoExpense_Cryo'] = ((data['CryoSleep'] == True) & (data['TotalExpense'] == 0)).astype(object)\n    data['Cryo_VIP'] = data['CryoSleep'].astype(str) + '_' + data['VIP'].astype(str)\n    data['Planet_AgeGroup'] = data['HomePlanet'].astype(str) + '_' + data['AgeGroup'].astype(str)\n    data['Deck_Side'] = data['Deck'].astype(str) + '_' + data['Side'].astype(str)\n    data['Full_Travel_Combo'] = (data['HomePlanet'].astype(str) + '_' + \n                                 data['Destination'].astype(str) + '_' + \n                                 data['CryoSleep'].astype(str))\n    if 'FamilyName' in data.columns:\n        data['Family_Group'] = data['FamilyName'].astype(str) + '_' + data['PassengerGroup'].astype(str)\n    else:\n        data['Family_Group'] = np.nan\n    return data\n\n# =========================================================\n# 2. 特徴量生成とデータ準備\n# =========================================================\ntrain_features = create_features(train)\ntest_features = create_features(test)\n\nfeature_cols = [\n    'HomePlanet', 'CryoSleep', 'Destination', 'VIP',\n    'Side', 'Num',\n    'TwoExpense', 'ThreeExpense', 'AgeGroup',\n    'Cabin_Loc', 'NoExpense_Cryo', 'Cryo_VIP', 'Planet_AgeGroup',\n    'Deck_Side', 'Full_Travel_Combo',\n]\n\nX_full = train_features[feature_cols].copy()\nX_test_full = test_features[feature_cols].copy()\ny_full = train['Transported']\n\ncategorical_features = [\n    'HomePlanet', 'CryoSleep', 'Destination', 'VIP',\n    'Side', 'AgeGroup',\n    'Cabin_Loc', 'NoExpense_Cryo', 'Cryo_VIP', 'Planet_AgeGroup',\n    'Deck_Side', 'Full_Travel_Combo',\n]\n\nfor col in categorical_features:\n    X_full[col] = X_full[col].astype(str).replace('nan', 'NA').replace('None', 'NA')\n    X_test_full[col] = X_test_full[col].astype(str).replace('nan', 'NA').replace('None', 'NA')\n\ngroups = train_features['PassengerGroup'].fillna('Unknown').astype(str)\n\nprint(f\"使用特徴量数: {len(feature_cols)}\")\nprint(f\"特徴量一覧: {feature_cols}\")\nprint(f\"データシェイプ: Train {X_full.shape}, Test {X_test_full.shape}\")\n\n# =========================================================\n# 3. Optunaの最良パラメータを適用\n# =========================================================\n\n# ★ Optunaの最良パラメータを直接使用\nbest_params_optuna = {\n    'iterations': 183,\n    'learning_rate': 0.08479043292417315,\n    'depth': 3,\n    'l2_leaf_reg': 0.00010707258143447216,\n    'border_count': 253,\n}\n\nparams_cat = {\n    'loss_function': 'Logloss',\n    'eval_metric': 'Accuracy',\n    'random_seed': 42,\n    'verbose': 0,\n    'allow_writing_files': False,\n}\nparams_cat.update(best_params_optuna)\n\n# =========================================================\n# 4. 5分割CVによる最適なイテレーション数の再決定\n# =========================================================\nscores_full = []\nfeature_importance_list = []\nbest_iterations_list = [] \n\ncv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=420)\n\nprint(\"\\n=== 5-Fold Cross Validation (Optunaパラメータ + Early Stopping) ===\")\nfor fold_idx, (trn_idx, val_idx) in enumerate(cv.split(X_full, y_full, groups=groups), start=1):\n    X_train_full, X_valid_full = X_full.iloc[trn_idx], X_full.iloc[val_idx]\n    y_train_full, y_valid_full = y_full.iloc[trn_idx], y_full.iloc[val_idx]\n\n    # Initialize model with Optuna's best params\n    model = cb.CatBoostClassifier(**params_cat)\n    model.fit(\n        X_train_full, y_train_full,\n        cat_features=categorical_features,\n        eval_set=(X_valid_full, y_valid_full),\n        early_stopping_rounds=50, \n    )\n    \n    best_iterations_list.append(model.get_best_iteration())\n\n    y_pred_full = model.predict(X_valid_full)\n    acc_full = accuracy_score(y_valid_full, y_pred_full)\n    scores_full.append(acc_full)\n\n    feature_importance_list.append(model.get_feature_importance())\n\n    print(f\"Fold {fold_idx} accuracy: {acc_full:.5f} (Best Iter: {model.get_best_iteration()})\")\n\n# =========================================================\n# 5. 結果まとめと最終モデル学習\n# =========================================================\nmean_best_iterations = int(np.mean(best_iterations_list))\n\nprint(\"=\" * 50)\nprint(f\"Mean CV accuracy (CatBoost, Optuna Params): {np.mean(scores_full):.5f}\")\nprint(f\"Standard deviation: {np.std(scores_full):.5f}\")\nprint(f\"Mean Best Iterations (for final model): {mean_best_iterations}\")\nprint(\"=\" * 50)\n\n\nfeature_importance_avg = np.mean(feature_importance_list, axis=0)\nfeature_importance_df = pd.DataFrame({\n    'feature': X_full.columns,\n    'importance': feature_importance_avg\n}).sort_values('importance', ascending=False)\n\nprint(\"\\n=== Top 10 重要特徴量 (CatBoost) ===\")\nprint(feature_importance_df.head(10).to_string(index=False))\n\n# =========================================================\n# 6. 全データで再学習 (Best Iterationsを適用)\n# =========================================================\nparams_final = params_cat.copy()\n# CVで得られた平均最適なイテレーション数に上書き\nparams_final['iterations'] = mean_best_iterations\n\nprint(f\"\\n=== 全データで最終モデルを学習 (CatBoost, Iterations={mean_best_iterations}, Optuna Params) ===\")\nfinal_model = cb.CatBoostClassifier(**params_final)\nfinal_model.fit(X_full, y_full, cat_features=categorical_features)\nprint(\"最終モデル学習完了\")\n\n# =========================================================\n# 7. 提出ファイルの作成\n# =========================================================\npreds = final_model.predict(X_test_full)\n\npassenger_ids = test[\"PassengerId\"]\n\noutput = pd.DataFrame({'PassengerId': passenger_ids,\n                       'Transported': preds.astype(bool)})\n\noutput.to_csv('/kaggle/working/submission.csv', index=False)\nprint(\"\\n提出ファイルの先頭5行:\")\nprint(output.head())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-18T08:24:23.193730Z","iopub.execute_input":"2025-10-18T08:24:23.193974Z","iopub.status.idle":"2025-10-18T08:24:29.078937Z","shell.execute_reply.started":"2025-10-18T08:24:23.193953Z","shell.execute_reply":"2025-10-18T08:24:29.077275Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/1487352516.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/spaceship-titanic/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/spaceship-titanic/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/spaceship-titanic/train.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/spaceship-titanic/train.csv'","output_type":"error"}],"execution_count":1}]}